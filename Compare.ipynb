{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHdcvMFVuvTIOjyIxMFTXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sevenjunebaby/AiModels/blob/main/Compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing randomized search and grid search for hyperparameter estimation"
      ],
      "metadata": {
        "id": "dbXYMKr1lDxt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYS3i0Crk9Gg",
        "outputId": "e373168a-34d4-4c01-9a38-8df281e474e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomizedSearchCV took 6.41 seconds for 15 candidates parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.993 (std: 0.007)\n",
            "Parameters: {'alpha': np.float64(0.05690276955830174), 'average': False, 'l1_ratio': np.float64(0.13822256090399687)}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.983 (std: 0.017)\n",
            "Parameters: {'alpha': np.float64(0.09460058024709554), 'average': False, 'l1_ratio': np.float64(0.7468127201182538)}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.983 (std: 0.012)\n",
            "Parameters: {'alpha': np.float64(0.02191695691943531), 'average': False, 'l1_ratio': np.float64(0.9912520987971161)}\n",
            "\n",
            "GridSearchCV took 13.24 seconds for 60 candidate parameter settings.\n",
            "Model with rank: 1\n",
            "Mean validation score: 0.994 (std: 0.007)\n",
            "Parameters: {'alpha': np.float64(0.01), 'average': False, 'l1_ratio': np.float64(0.8888888888888888)}\n",
            "\n",
            "Model with rank: 2\n",
            "Mean validation score: 0.993 (std: 0.011)\n",
            "Parameters: {'alpha': np.float64(0.01), 'average': False, 'l1_ratio': np.float64(1.0)}\n",
            "\n",
            "Model with rank: 3\n",
            "Mean validation score: 0.989 (std: 0.009)\n",
            "Parameters: {'alpha': np.float64(0.01), 'average': False, 'l1_ratio': np.float64(0.0)}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# get some data\n",
        "X, y = load_digits(return_X_y=True, n_class=3)\n",
        "\n",
        "# build a classifier\n",
        "clf = SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True)\n",
        "\n",
        "\n",
        "# Utility function to report best scores\n",
        "def report(results, n_top=3):\n",
        "    for i in range(1, n_top + 1):\n",
        "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
        "        for candidate in candidates:\n",
        "            print(\"Model with rank: {0}\".format(i))\n",
        "            print(\n",
        "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
        "                    results[\"mean_test_score\"][candidate],\n",
        "                    results[\"std_test_score\"][candidate],\n",
        "                )\n",
        "            )\n",
        "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
        "            print(\"\")\n",
        "\n",
        "\n",
        "# specify parameters and distributions to sample from\n",
        "param_dist = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": stats.uniform(0, 1),\n",
        "    \"alpha\": stats.loguniform(1e-2, 1e0),\n",
        "}\n",
        "\n",
        "# run randomized search\n",
        "n_iter_search = 15\n",
        "random_search = RandomizedSearchCV(\n",
        "    clf, param_distributions=param_dist, n_iter=n_iter_search\n",
        ")\n",
        "\n",
        "start = time()\n",
        "random_search.fit(X, y)\n",
        "print(\n",
        "    \"RandomizedSearchCV took %.2f seconds for %d candidates parameter settings.\"\n",
        "    % ((time() - start), n_iter_search)\n",
        ")\n",
        "report(random_search.cv_results_)\n",
        "\n",
        "# use a full grid over all parameters\n",
        "param_grid = {\n",
        "    \"average\": [True, False],\n",
        "    \"l1_ratio\": np.linspace(0, 1, num=10),\n",
        "    \"alpha\": np.power(10, np.arange(-2, 1, dtype=float)),\n",
        "}\n",
        "\n",
        "# run grid search\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
        "start = time()\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "print(\n",
        "    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
        "    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
        ")\n",
        "report(grid_search.cv_results_)"
      ]
    }
  ]
}